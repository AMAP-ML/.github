# AMAP-ML

ğŸ¤– **Machine Learning @ Amap (AutoNavi), Alibaba Group**

We are the Machine Learning team at [Amap](https://amap.com/) (AutoNavi), focusing on delivering AI product and cutting-edge research in large language models, computer vision, generative AI, agent, world models and intelligent mobility. Our work has been published at top-tier venues including **ICLR, AAAI, ICCV, EMNLP, ACM MM, and WWW**.

---

## ğŸ”¥ News

- **2026.02.06** ğŸ’» We open-sourced [MobilityBench](https://github.com/AMAP-ML/MobilityBench) -- A Scalable Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios.
- **2026.02.06** ğŸ‰ [SpatialGenEval](https://github.com/AMAP-ML/SpatialGenEval) is accepted by **ICLR 2026** -- Benchmarking Spatial Intelligence of Text-to-Image Models.
- **2026.02.06** ğŸ‰ [Tree-GRPO](https://github.com/AMAP-ML/Tree-GRPO) is accepted by **ICLR 2026** -- Tree Search for LLM Agent Reinforcement Learning.
- **2026.02.06** ğŸ‰ [S2-Guidance](https://github.com/AMAP-ML/S2-Guidance) is accepted by **ICLR 2026** -- Stochastic Self-Guidance for Training-Free Enhancement of Diffusion Models.
- **2026.02.05** ğŸ‰ [MathForge](https://github.com/AMAP-ML/MathForge) is accepted by **ICLR 2026** -- Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation.
- **2026.02.04** ğŸ’» We open-sourced [Code2World](https://github.com/AMAP-ML/Code2World) -- A GUI World Model via Renderable Code Generation.
- **2026.02.04** ğŸ‰ [GPG](https://github.com/AMAP-ML/GPG) is accepted by **ICLR 2026** -- A Simple and Strong Reinforcement Learning Baseline for Model Reasoning.
- **2026.02.04** ğŸ‰ [NarrLV](https://github.com/AMAP-ML/NarrLV) is accepted by **ICLR 2026** -- A Comprehensive Narrative-Centric Evaluation for Long Video Generation Models.
- **2026.02.04** ğŸ‰ [EPG](https://github.com/AMAP-ML/EPG) is accepted by **ICLR 2026** -- Advancing End-To-End Pixel-Space Generative Modeling via Self-Supervised Pre-Training.
- **2026.02.04** ğŸ‰ [Omni-Effects](https://github.com/AMAP-ML/Omni-Effects) is accepted by **AAAI 2026**.
- **2026.02.04** ğŸ‰ [ImagerySearch](https://github.com/AMAP-ML/ImagerySearch) is accepted by **AAAI 2026** -- Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints.
- **2026.02.04** ğŸ‰ [Pos2Distill](https://github.com/AMAP-ML/Pos2Distill) is accepted by **EMNLP 2025** -- Position Bias Mitigated via Inter-Position Knowledge Distillation.
- **2026.02.04** ğŸ‰ [DSFNet](https://github.com/AMAP-ML/DSFNet) is accepted by **WWW 2025** -- Disentangled Scenario Factorization for Multi-Scenario Route Ranking.
- **2026.02.04** ğŸ‰ [UPRE](https://github.com/AMAP-ML/UPRE) is accepted by **CCV 2025** -- Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement.
- **2026.02.03** ğŸ‰ [LD-RPS](https://github.com/AMAP-ML/LD-RPS) is accepted by **ICCV 2025**.
- **2026.02.02** ğŸ’» We open-sourced [AR-MAP](https://github.com/AMAP-ML/AR-MAP).
- **2026.02.02** ğŸ‰ [VMBench](https://github.com/AMAP-ML/VMBench) is accepted by **ICCV 2025** -- A Benchmark for Perception-Aligned Video Motion Generation.
- **2026.01.31** ğŸ‰ [SocioReasoner](https://github.com/AMAP-ML/SocioReasoner) is accepted by **ICLR 2026** -- Urban Socio-Semantic Segmentation with Vision-Language Reasoning.
- **2026.01.29** ğŸ’» We open-sourced [SpatialGenEval](https://github.com/AMAP-ML/SpatialGenEval) -- Benchmarking Spatial Intelligence of Text-to-Image Models.
- **2026.01.28** ğŸ’» We open-sourced [MathForge](https://github.com/AMAP-ML/MathForge) -- Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation.
- **2026.01.23** ğŸ’» We open-sourced [STV](https://github.com/AMAP-ML/STV) -- Sensitivity-Aware Task Vectors for Many-Shot Multimodal In-Context Learning.
- **2026.01.21** ğŸ‰ [USP](https://github.com/AMAP-ML/USP) is accepted by **ICCV 2025** -- Unified Self-Supervised Pretraining for Image Generation and Understanding.
- **2026.01.15** ğŸ’» We open-sourced [SocioReasoner](https://github.com/AMAP-ML/SocioReasoner) -- Urban Socio-Semantic Segmentation with Vision-Language Reasoning.
- **2026.01.13** ğŸ‰ [FingER](https://github.com/AMAP-ML/FingER) is accepted by **ACM MM 2025** -- Content-Aware Fine-grained Evaluation with Reasoning for AI-Generated Videos.
- **2026.01.13** ğŸ‰ [HS-STaR](https://github.com/AMAP-ML/HS-STaR) is accepted by **EMNLP 2025** -- Hierarchical Sampling for Self-Taught Reasoners via Difficulty Estimation and Budget Reallocation.
- **2026.01.13** ğŸ‰ [SCALAR](https://github.com/AMAP-ML/SCALAR) is accepted by **AAAI 2026** -- Scale-wise Controllable Visual Autoregressive Learning.
- **2026.01.07** ğŸ’» We open-sourced [Thinking-with-Map](https://github.com/AMAP-ML/Thinking-with-Map) -- Reinforced Parallel Map-Augmented Agent for Geolocalization.
- **2025.11.25** ğŸ’» We open-sourced [SCALAR](https://github.com/AMAP-ML/SCALAR) -- Scale-wise Controllable Visual Autoregressive Learning.
- **2025.11.18** ğŸ’» We open-sourced [Eevee](https://github.com/AMAP-ML/Eevee) -- Towards Close-up High-resolution Video-based Virtual Try-on.
- **2025.10.22** ğŸ’» We open-sourced [Taming-Hallucinations](https://github.com/AMAP-ML/Taming-Hallucinations).
- **2025.10.14** ğŸ’» We open-sourced [EPG](https://github.com/AMAP-ML/EPG) -- Advancing End-To-End Pixel-Space Generative Modeling via Self-Supervised Pre-Training.
- **2025.09.27** ğŸ’» We open-sourced [HS-STaR](https://github.com/AMAP-ML/HS-STaR) -- Hierarchical Sampling for Self-Taught Reasoners via Difficulty Estimation and Budget Reallocation.
- **2025.09.25** ğŸ’» We open-sourced [Tree-GRPO](https://github.com/AMAP-ML/Tree-GRPO) -- Tree Search for LLM Agent Reinforcement Learning.
- **2025.09.09** ğŸ’» We open-sourced [DSFNet](https://github.com/AMAP-ML/DSFNet) -- Disentangled Scenario Factorization for Multi-Scenario Route Ranking.
- **2025.08.29** ğŸ’» We open-sourced [Pos2Distill](https://github.com/AMAP-ML/Pos2Distill) -- Position Bias Mitigated via Inter-Position Knowledge Distillation.
- **2025.08.28** ğŸ’» We open-sourced [FE2E](https://github.com/AMAP-ML/FE2E).
- **2025.08.18** ğŸ’» We open-sourced [ImagerySearch](https://github.com/AMAP-ML/ImagerySearch) -- Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints.
- **2025.08.15** ğŸ’» We open-sourced [S2-Guidance](https://github.com/AMAP-ML/S2-Guidance) -- Stochastic Self-Guidance for Training-Free Enhancement of Diffusion Models.
- **2025.08.11** ğŸ’» We open-sourced [Omni-Effects](https://github.com/AMAP-ML/Omni-Effects).
- **2025.07.16** ğŸ’» We open-sourced [UPRE](https://github.com/AMAP-ML/UPRE) -- Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement.
- **2025.07.03** ğŸ’» We open-sourced [LD-RPS](https://github.com/AMAP-ML/LD-RPS).
- **2025.06.20** ğŸ’» We open-sourced [FluxText](https://github.com/AMAP-ML/FluxText) -- A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing.
- **2025.05.28** ğŸ’» We open-sourced [FingER](https://github.com/AMAP-ML/FingER) -- Content-Aware Fine-grained Evaluation with Reasoning for AI-Generated Videos.
- **2025.05.21** ğŸ’» We open-sourced [UniVG-R1](https://github.com/AMAP-ML/UniVG-R1) -- Reasoning Guided Universal Visual Grounding with Reinforcement Learning.
- **2025.05.09** ğŸ’» We open-sourced [NarrLV](https://github.com/AMAP-ML/NarrLV) -- A Comprehensive Narrative-Centric Evaluation for Long Video Generation Models.
- **2025.04.07** ğŸ’» We open-sourced [RealQA](https://github.com/AMAP-ML/RealQA) -- Realistic Image Quality and Aesthetic Scoring with Multimodal LLM.
- **2025.04.03** ğŸ’» We open-sourced [GPG](https://github.com/AMAP-ML/GPG) -- A Simple and Strong Reinforcement Learning Baseline for Model Reasoning.
- **2025.03.12** ğŸ’» We open-sourced [VMBench](https://github.com/AMAP-ML/VMBench) -- A Benchmark for Perception-Aligned Video Motion Generation.
- **2025.03.11** ğŸ’» We open-sourced [USP](https://github.com/AMAP-ML/USP) -- Unified Self-Supervised Pretraining for Image Generation and Understanding.

---

## ğŸ“š Research Areas

### ğŸ§  LLM Reasoning & Reinforcement Learning

| Repository | Description | Venue |
|:--|:--|:--|
| [Tree-GRPO](https://github.com/AMAP-ML/Tree-GRPO) | Tree Search for LLM Agent Reinforcement Learning | ICLR 2026 |
| [GPG](https://github.com/AMAP-ML/GPG) | A Simple and Strong Reinforcement Learning Baseline for Model Reasoning | ICLR 2026 |
| [MathForge](https://github.com/AMAP-ML/MathForge) | Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation | ICLR 2026 |
| [HS-STaR](https://github.com/AMAP-ML/HS-STaR) | Hierarchical Sampling for Self-Taught Reasoners via Difficulty Estimation and Budget Reallocation | EMNLP 2025 |
| [Pos2Distill](https://github.com/AMAP-ML/Pos2Distill) | Position Bias Mitigated via Inter-Position Knowledge Distillation | EMNLP 2025 |

### ğŸ¨ Image Generation & Editing

| Repository | Description | Venue |
|:--|:--|:--|
| [FluxText](https://github.com/AMAP-ML/FluxText) | A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing | - |
| [S2-Guidance](https://github.com/AMAP-ML/S2-Guidance) | Stochastic Self-Guidance for Training-Free Enhancement of Diffusion Models | ICLR 2026 |
| [EPG](https://github.com/AMAP-ML/EPG) | Advancing End-To-End Pixel-Space Generative Modeling via Self-Supervised Pre-Training | ICLR 2026 |
| [Omni-Effects](https://github.com/AMAP-ML/Omni-Effects) | Omni-Effects: Implementation Code | AAAI 2026 |
| [SCALAR](https://github.com/AMAP-ML/SCALAR) | Scale-wise Controllable Visual Autoregressive Learning | AAAI 2026 |
| [USP](https://github.com/AMAP-ML/USP) | Unified Self-Supervised Pretraining for Image Generation and Understanding | ICCV 2025 |
| [SpatialGenEval](https://github.com/AMAP-ML/SpatialGenEval) | Benchmarking Spatial Intelligence of Text-to-Image Models | ICLR 2026 |

### ğŸ¬ Video Generation & Understanding

| Repository | Description | Venue |
|:--|:--|:--|
| [NarrLV](https://github.com/AMAP-ML/NarrLV) | A Comprehensive Narrative-Centric Evaluation for Long Video Generation Models | ICLR 2026 |
| [ImagerySearch](https://github.com/AMAP-ML/ImagerySearch) | Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints | AAAI 2026 |
| [VMBench](https://github.com/AMAP-ML/VMBench) | A Benchmark for Perception-Aligned Video Motion Generation | ICCV 2025 |
| [Eevee](https://github.com/AMAP-ML/Eevee) | Towards Close-up High-resolution Video-based Virtual Try-on | - |
| [FingER](https://github.com/AMAP-ML/FingER) | Content-Aware Fine-grained Evaluation with Reasoning for AI-Generated Videos | ACM MM 2025 |
| [FE2E](https://github.com/AMAP-ML/FE2E) | - | - |

### ğŸ‘ï¸ Multimodal & Vision-Language Models

| Repository | Description | Venue |
|:--|:--|:--|
| [UniVG-R1](https://github.com/AMAP-ML/UniVG-R1) | Reasoning Guided Universal Visual Grounding with Reinforcement Learning | - |
| [SocioReasoner](https://github.com/AMAP-ML/SocioReasoner) | Urban Socio-Semantic Segmentation with Vision-Language Reasoning | ICLR 2026 |
| [RealQA](https://github.com/AMAP-ML/RealQA) | Realistic Image Quality and Aesthetic Scoring with Multimodal LLM | - |
| [Code2World](https://github.com/AMAP-ML/Code2World) | A GUI World Model via Renderable Code Generation | - |
| [Taming-Hallucinations](https://github.com/AMAP-ML/Taming-Hallucinations) | - | - |
| [STV](https://github.com/AMAP-ML/STV) | Sensitivity-Aware Task Vectors for Many-Shot Multimodal In-Context Learning | - |

### ğŸ—ºï¸ Maps, Mobility & Spatial Intelligence

| Repository | Description | Venue |
|:--|:--|:--|
| [Thinking-with-Map](https://github.com/AMAP-ML/Thinking-with-Map) | Reinforced Parallel Map-Augmented Agent for Geolocalization | - |
| [MobilityBench](https://github.com/AMAP-ML/MobilityBench) | A Scalable Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios | - |
| [DSFNet](https://github.com/AMAP-ML/DSFNet) | Learning Disentangled Scenario Factorization for Multi-Scenario Route Ranking | WWW 2025 |
| [AR-MAP](https://github.com/AMAP-ML/AR-MAP) | - | - |

### ğŸ” Object Detection & Segmentation

| Repository | Description | Venue |
|:--|:--|:--|
| [UPRE](https://github.com/AMAP-ML/UPRE) | Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement | CCV 2025 |
| [LD-RPS](https://github.com/AMAP-ML/LD-RPS) | LD-RPS | ICCV 2025 |
