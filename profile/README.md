# AMAP-ML

ü§ñ **Machine Learning @ Amap (AutoNavi), Alibaba Group**

We are the Machine Learning team at [Amap](https://amap.com/) (AutoNavi), focusing on AI product and cutting-edge research in large language models, computer vision, generative AI, and intelligent mobility. Our work has been published at top-tier venues including **ICLR, AAAI, ICCV, EMNLP, ACM MM, and WWW**.

---

## üî• News

- **2026.02** üíª We open-sourced [MobilityBench](https://github.com/AMAP-ML/MobilityBench) -- A Scalable Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios.
- **2026.02** üíª We open-sourced [Code2World](https://github.com/AMAP-ML/Code2World) -- A GUI World Model via Renderable Code Generation.
- **2026.02** üíª We open-sourced [AR-MAP](https://github.com/AMAP-ML/AR-MAP).
- **2026.01** üéâ [SpatialGenEval](https://github.com/AMAP-ML/SpatialGenEval) is accepted by **ICLR 2026** -- Benchmarking Spatial Intelligence of Text-to-Image Models.
- **2026.01** üéâ [MathForge](https://github.com/AMAP-ML/MathForge) is accepted by **ICLR 2026** -- Boosting Mathematical Reasoning via Difficulty-Aware GRPO.
- **2026.01** üíª We open-sourced [STV](https://github.com/AMAP-ML/STV) -- Sensitivity-Aware Task Vectors for Many-Shot Multimodal In-Context Learning.
- **2026.01** üéâ [SocioReasoner](https://github.com/AMAP-ML/SocioReasoner) is accepted by **ICLR 2026** -- Urban Socio-Semantic Segmentation with Vision-Language Reasoning.
- **2026.01** üíª We open-sourced [Thinking-with-Map](https://github.com/AMAP-ML/Thinking-with-Map) -- Reinforced Parallel Map-Augmented Agent for Geolocalization.
- **2025.11** üéâ [SCALAR](https://github.com/AMAP-ML/SCALAR) is accepted by **AAAI 2026** -- Scale-wise Controllable Visual Autoregressive Learning.
- **2025.11** üíª We open-sourced [Eevee](https://github.com/AMAP-ML/Eevee) -- Towards Close-up High-resolution Video-based Virtual Try-on.
- **2025.10** üíª We open-sourced [Taming-Hallucinations](https://github.com/AMAP-ML/Taming-Hallucinations).
- **2025.10** üéâ [EPG](https://github.com/AMAP-ML/EPG) is accepted by **ICLR 2026** -- Advancing End-To-End Pixel-Space Generative Modeling via Self-Supervised Pre-Training.
- **2025.09** üéâ [Tree-GRPO](https://github.com/AMAP-ML/Tree-GRPO) is accepted by **ICLR 2026** -- Tree Search for LLM Agent Reinforcement Learning.
- **2025.09** üéâ [HS-STaR](https://github.com/AMAP-ML/HS-STaR) is accepted by **EMNLP 2025** -- Hierarchical Sampling for Self-Taught Reasoners.
- **2025.09** üéâ [DSFNet](https://github.com/AMAP-ML/DSFNet) is accepted by **WWW 2025** -- Disentangled Scenario Factorization for Multi-Scenario Route Ranking.
- **2025.08** üíª We open-sourced [FE2E](https://github.com/AMAP-ML/FE2E).
- **2025.08** üéâ [Pos2Distill](https://github.com/AMAP-ML/Pos2Distill) is accepted by **EMNLP 2025** -- Position Bias Mitigated via Inter-Position Knowledge Distillation.
- **2025.08** üéâ [ImagerySearch](https://github.com/AMAP-ML/ImagerySearch) is accepted by **AAAI 2026** -- Adaptive Test-Time Search for Video Generation.
- **2025.08** üéâ [S2-Guidance](https://github.com/AMAP-ML/S2-Guidance) is accepted by **ICLR 2026** -- Stochastic Self-Guidance for Training-Free Enhancement of Diffusion Models.
- **2025.08** üéâ [Omni-Effects](https://github.com/AMAP-ML/Omni-Effects) is accepted by **AAAI 2026**.
- **2025.07** üéâ [UPRE](https://github.com/AMAP-ML/UPRE) is accepted by **CCV 2025** -- Zero-Shot Domain Adaptation for Object Detection.
- **2025.07** üéâ [LD-RPS](https://github.com/AMAP-ML/LD-RPS) is accepted by **ICCV 2025**.
- **2025.06** üíª We open-sourced [FluxText](https://github.com/AMAP-ML/FluxText) -- A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing.
- **2025.05** üéâ [FingER](https://github.com/AMAP-ML/FingER) is accepted by **ACM MM 2025** -- Content-Aware Fine-grained Evaluation for AI-Generated Videos.
- **2025.05** üíª We open-sourced [UniVG-R1](https://github.com/AMAP-ML/UniVG-R1) -- Reasoning Guided Universal Visual Grounding with Reinforcement Learning.
- **2025.05** üéâ [NarrLV](https://github.com/AMAP-ML/NarrLV) is accepted by **ICLR 2026** -- Narrative-Centric Evaluation for Long Video Generation Models.
- **2025.04** üíª We open-sourced [RealQA](https://github.com/AMAP-ML/RealQA) -- Realistic Image Quality and Aesthetic Scoring with Multimodal LLM.
- **2025.04** üéâ [GPG](https://github.com/AMAP-ML/GPG) is accepted by **ICLR 2026** -- A Simple and Strong Reinforcement Learning Baseline for Model Reasoning.
- **2025.03** üéâ [VMBench](https://github.com/AMAP-ML/VMBench) is accepted by **ICCV 2025** -- A Benchmark for Perception-Aligned Video Motion Generation.
- **2025.03** üéâ [USP](https://github.com/AMAP-ML/USP) is accepted by **ICCV 2025** -- Unified Self-Supervised Pretraining for Image Generation and Understanding.

---

## üìö Research Areas

### üß† LLM Reasoning & Reinforcement Learning

| Repository | Description | Venue |
|:--|:--|:--|
| [Tree-GRPO](https://github.com/AMAP-ML/Tree-GRPO) | Tree Search for LLM Agent Reinforcement Learning | ICLR 2026 |
| [GPG](https://github.com/AMAP-ML/GPG) | A Simple and Strong Reinforcement Learning Baseline for Model Reasoning | ICLR 2026 |
| [MathForge](https://github.com/AMAP-ML/MathForge) | Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation | ICLR 2026 |
| [HS-STaR](https://github.com/AMAP-ML/HS-STaR) | Hierarchical Sampling for Self-Taught Reasoners via Difficulty Estimation and Budget Reallocation | EMNLP 2025 |
| [Pos2Distill](https://github.com/AMAP-ML/Pos2Distill) | Position Bias Mitigated via Inter-Position Knowledge Distillation | EMNLP 2025 |

### üé® Image Generation & Editing

| Repository | Description | Venue |
|:--|:--|:--|
| [FluxText](https://github.com/AMAP-ML/FluxText) | A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing | - |
| [S2-Guidance](https://github.com/AMAP-ML/S2-Guidance) | Stochastic Self-Guidance for Training-Free Enhancement of Diffusion Models | ICLR 2026 |
| [EPG](https://github.com/AMAP-ML/EPG) | Advancing End-To-End Pixel-Space Generative Modeling via Self-Supervised Pre-Training | ICLR 2026 |
| [Omni-Effects](https://github.com/AMAP-ML/Omni-Effects) | Omni-Effects: Implementation Code | AAAI 2026 |
| [SCALAR](https://github.com/AMAP-ML/SCALAR) | Scale-wise Controllable Visual Autoregressive Learning | AAAI 2026 |
| [USP](https://github.com/AMAP-ML/USP) | Unified Self-Supervised Pretraining for Image Generation and Understanding | ICCV 2025 |
| [SpatialGenEval](https://github.com/AMAP-ML/SpatialGenEval) | Benchmarking Spatial Intelligence of Text-to-Image Models | ICLR 2026 |

### üé¨ Video Generation & Understanding

| Repository | Description | Venue |
|:--|:--|:--|
| [NarrLV](https://github.com/AMAP-ML/NarrLV) | A Comprehensive Narrative-Centric Evaluation for Long Video Generation Models | ICLR 2026 |
| [ImagerySearch](https://github.com/AMAP-ML/ImagerySearch) | Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints | AAAI 2026 |
| [VMBench](https://github.com/AMAP-ML/VMBench) | A Benchmark for Perception-Aligned Video Motion Generation | ICCV 2025 |
| [Eevee](https://github.com/AMAP-ML/Eevee) | Towards Close-up High-resolution Video-based Virtual Try-on | - |
| [FingER](https://github.com/AMAP-ML/FingER) | Content-Aware Fine-grained Evaluation with Reasoning for AI-Generated Videos | ACM MM 2025 |
| [FE2E](https://github.com/AMAP-ML/FE2E) | - | - |

### üëÅÔ∏è Multimodal & Vision-Language Models

| Repository | Description | Venue |
|:--|:--|:--|
| [UniVG-R1](https://github.com/AMAP-ML/UniVG-R1) | Reasoning Guided Universal Visual Grounding with Reinforcement Learning | - |
| [SocioReasoner](https://github.com/AMAP-ML/SocioReasoner) | Urban Socio-Semantic Segmentation with Vision-Language Reasoning | ICLR 2026 |
| [RealQA](https://github.com/AMAP-ML/RealQA) | Realistic Image Quality and Aesthetic Scoring with Multimodal LLM | - |
| [Code2World](https://github.com/AMAP-ML/Code2World) | A GUI World Model via Renderable Code Generation | - |
| [Taming-Hallucinations](https://github.com/AMAP-ML/Taming-Hallucinations) | - | - |
| [STV](https://github.com/AMAP-ML/STV) | Sensitivity-Aware Task Vectors for Many-Shot Multimodal In-Context Learning | - |

### üó∫Ô∏è Maps, Mobility & Spatial Intelligence

| Repository | Description | Venue |
|:--|:--|:--|
| [Thinking-with-Map](https://github.com/AMAP-ML/Thinking-with-Map) | Reinforced Parallel Map-Augmented Agent for Geolocalization | - |
| [MobilityBench](https://github.com/AMAP-ML/MobilityBench) | A Scalable Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios | - |
| [DSFNet](https://github.com/AMAP-ML/DSFNet) | Learning Disentangled Scenario Factorization for Multi-Scenario Route Ranking | WWW 2025 |
| [AR-MAP](https://github.com/AMAP-ML/AR-MAP) | - | - |

### üîç Object Detection & Segmentation

| Repository | Description | Venue |
|:--|:--|:--|
| [UPRE](https://github.com/AMAP-ML/UPRE) | Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement | CCV 2025 |
| [LD-RPS](https://github.com/AMAP-ML/LD-RPS) | LD-RPS | ICCV 2025 |
